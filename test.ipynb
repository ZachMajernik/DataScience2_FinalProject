{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from gymnasium.wrappers import FrameStack\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"ALE/Tetris-v5\", render_mode='human')\n",
    "env.reset()\n",
    "done = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_size = env.observation_space.shape\n",
    "action_size = env.action_space.n\n",
    "batch_size = 64\n",
    "gamma = 0.95\n",
    "episodes = 10\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, action_size):\n",
    "    model = Sequential([ # Each person should change the amount of Conv2D/Dense layers, as well as the filter amount and kernel_size/strides\n",
    "        Conv2D(32, kernel_size=(8, 8), strides=(4, 4), activation='relu', input_shape=input_shape),\n",
    "        Conv2D(64, kernel_size=(4, 4), strides=(2, 2), activation='relu'),\n",
    "        Conv2D(64, kernel_size=(3, 3), strides=(1, 1), activation='relu'),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dense(action_size, activation='linear')\n",
    "    ])\n",
    "    # model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xygni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "dqn = build_model(state_size, action_size)\n",
    "dqn.load_weights('brennan.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_rgb(state):\n",
    "    state = cv2.resize(state, (84, 110))\n",
    "    state = cv2.cvtColor(state, cv2.COLOR_BGR2GRAY)\n",
    "    state = state[26:110, :]\n",
    "    state = state.astype(np.float32) / 255.0\n",
    "    return state.reshape(84, 84, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_grayscale(state):\n",
    "    if state is None:\n",
    "        return np.zeros((84, 84, 1), dtype=np.float32)  # Return a blank image if state is None\n",
    "    state = cv2.cvtColor(state, cv2.COLOR_RGB2GRAY) if state.shape[-1] == 3 else state  # Convert RGB to grayscale if needed\n",
    "    state = cv2.resize(state, (84, 84))  # Resize the image\n",
    "    state = state.astype(np.float32) / 255.0  # Normalize pixel values\n",
    "    return np.expand_dims(state, axis=-1)  # Ensure the image has a single channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       " \n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       " \n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [ 50, 132,  50],\n",
       "         [ 50, 132,  50],\n",
       "         [ 50, 132,  50]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       " \n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       " \n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]]], dtype=uint8),\n",
       " 0.0,\n",
       " False,\n",
       " False,\n",
       " {'lives': 0, 'episode_frame_number': 4, 'frame_number': 4})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a random action\n",
    "action = env.action_space.sample()\n",
    "\n",
    "# Perform the action and capture the return values in a single variable\n",
    "info = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode Progress:   4%|‚ñç         | 4/100 [10:56<4:27:43, 167.32s/it]"
     ]
    }
   ],
   "source": [
    "for episode in tqdm(range(episodes), desc='Episode Progress'):\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        q_values = dqn.predict(np.array([state]), verbose=None)[0]\n",
    "        action = np.argmax(q_values)  # Exploitation\n",
    "\n",
    "        # Ensure action is within bounds\n",
    "        action = np.clip(action, 0, action_size - 1)\n",
    "\n",
    "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
